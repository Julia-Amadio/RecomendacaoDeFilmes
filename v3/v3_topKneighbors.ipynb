{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Esta abordagem é filtragem colaborativa baseada em itens (item-based collaborative filtering)\n",
        "!pip install pandas numpy scipy scikit-learn"
      ],
      "metadata": {
        "id": "d9JlDGD4OFIs"
      },
      "id": "d9JlDGD4OFIs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7e158e2-fade-45f4-9bad-44dec33cd0ce",
      "metadata": {
        "id": "f7e158e2-fade-45f4-9bad-44dec33cd0ce"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "#Configurar diretório e carregar dados\n",
        "!wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
        "!unzip ml-latest-small.zip\n",
        "\n",
        "dataset_dir = \"ml-latest-small\"\n",
        "\n",
        "#Carregar avaliações\n",
        "ratings = pd.read_csv(f\"{dataset_dir}/ratings.csv\")  #userId, movieId, rating, timestamp\n",
        "\n",
        "#Carregar filmes\n",
        "movies = pd.read_csv(f\"{dataset_dir}/movies.csv\")    #movieId, title, genres\n",
        "\n",
        "print(\"Dados carregados!\")\n",
        "print(f\"Total de avaliações: {len(ratings)}\")\n",
        "print(f\"Total de filmes: {len(movies)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "370882ff-4f30-43fb-b3fe-990eadbb4a49",
      "metadata": {
        "id": "370882ff-4f30-43fb-b3fe-990eadbb4a49"
      },
      "outputs": [],
      "source": [
        "#Mapear IDs para índices e criar matriz esparsa\n",
        "\n",
        "#O objetivo aqui é transformar os IDs originais (que não são sequenciais)\n",
        "#em índices contínuos (0, 1, 2, ...) — algo necessário para criar uma matriz.\n",
        "\n",
        "#Criaremos dicionários de mapeamento de IDs para índices\n",
        "#Cada linha em ratings representa uma avaliação feita por um usuário a um filme\n",
        "#Porém os IDs originais em ratings['userId'] e ratings['movieId'] podem não ser sequenciais.\n",
        "#Para criar matriz users x movies precisamos índices 0..N-1.\n",
        "\n",
        "#.unique() retorna um array NumPy contendo apenas os valores distintos de uma coluna, na ordem em que aparecem\n",
        "#enumerate() transforma uma sequência em pares (índice, valor)\n",
        "'''Se ratings.csv contiver:\n",
        "   | userId | movieId | rating |\n",
        "   | ------ | ------- | ------ |\n",
        "   | 10     | 5       | 3.5    |\n",
        "   | 42     | 2       | 4.0    |\n",
        "   | 10     | 7       | 2.0    |\n",
        "   Então user_mapper = {10: 0, 42: 1}, movie_mapper = {5: 0, 2: 1, 7: 2}\n",
        "   Usuário 10 vira linha 0, Usuário 42 vira linha 1\n",
        "   Filme 5 vira coluna 0, Filme 2 vira coluna 1, Filme 7 vira coluna 2\n",
        "   Matriz esparsa ficará com shape (2, 3) — 2 usuários × 3 filmes.\n",
        "'''\n",
        "\n",
        "#Cria mapeamento de cada userId único para um índice sequencial\n",
        "user_mapper = {uid: i for i, uid in enumerate(ratings['userId'].unique())}\n",
        "#Cria mapeamento de cada movieId único para um índice sequencial\n",
        "movie_mapper = {mid: i for i, mid in enumerate(ratings['movieId'].unique())}\n",
        "\n",
        "#Mapeamento inverso (para retornar IDs originais)\n",
        "movie_inv_mapper = {i: mid for mid, i in movie_mapper.items()}\n",
        "user_inv_mapper = {i: uid for uid, i in user_mapper.items()}\n",
        "\n",
        "#Mapear IDs originais para índices, adiciona colunas com os índices internos\n",
        "ratings['user_idx'] = ratings['userId'].map(user_mapper)\n",
        "ratings['movie_idx'] = ratings['movieId'].map(movie_mapper)\n",
        "\n",
        "#NOVO: normalização das notas + ponderação por similaridade\n",
        "#Usuários têm padrões de avaliação diferentes: uns dão sempre 5 estrelas, outros quase nunca passam de 3.5\n",
        "#Ao calcular a similaridade, devemos centralizar (subtrair a média de cada usuário)\n",
        "#Isso remove o “viés do usuário” e aumenta significativamente a qualidade preditiva do modelo\n",
        "#O modelo se aproxima mais de um Collaborative Filtering baseado em correlação de Pearson\n",
        "\n",
        "#Calcular média das notas por usuário\n",
        "user_mean = ratings.groupby('userId')['rating'].mean()\n",
        "#Subtrair a média de cada usuário\n",
        "ratings['rating_norm'] = ratings.apply(lambda x: x['rating'] - user_mean.loc[x['userId']], axis=1)\n",
        "\n",
        "#Criar matriz esparsa (usuários x filmes)\n",
        "ratings_sparse = csr_matrix(\n",
        "    (ratings['rating_norm'], (ratings['user_idx'], ratings['movie_idx']))\n",
        ")\n",
        "\n",
        "'''Com o exemplo usado antes:\n",
        "   user_mapper = {10: 0, 42: 1}\n",
        "   movie_mapper = {5: 0, 2: 1, 7: 2}\n",
        "   A matriz de usuários × filmes fica:        5     2     7\n",
        "                                       U10 [ 3.5   0.0   2.0 ]\n",
        "                                       U42 [ 0.0   4.0   0.0 ]\n",
        "   Então a representação esparsa (armazenando só valores != 0) fica:\n",
        "            (0,0)  3.5 --> user 10, movie 5\n",
        "            (0,2)  2.0 --> user 10, movie 7\n",
        "            (1,1)  4.0 --> user 42, movie 2\n",
        "'''\n",
        "\n",
        "print(\"Matriz esparsa criada!\")\n",
        "print(f\"Shape da matriz: {ratings_sparse.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "685545e9-51cd-4733-8996-32d64fc18d45",
      "metadata": {
        "id": "685545e9-51cd-4733-8996-32d64fc18d45"
      },
      "outputs": [],
      "source": [
        "#Calcular similaridade entre filmes\n",
        "\n",
        "#.T = operador de transposição. ratings_sparse tem usuários nas linhas e filmes nas colunas\n",
        "#Transposição é feita para ter filmes nas linhas (necessário para filme-filme similarity)\n",
        "#dense_output=False mantém saída esparsa.\n",
        "movie_similarity = cosine_similarity(ratings_sparse.T, dense_output=False)\n",
        "\n",
        "print(\"Matriz de similaridade entre filmes calculada!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Seleciona os Top-K vizinhos por item, ignorando similaridades negativas\n",
        "\n",
        "K = 100  #pode ser alterado livremente\n",
        "\n",
        "#Converte a matriz de similaridade para formato CSR para operações rápidas\n",
        "movie_similarity_csr = movie_similarity.tocsr()\n",
        "\n",
        "#Inicializa lista para armazenar os índices e valores de similaridade dos Top-K vizinhos\n",
        "indices_topk = []\n",
        "values_topk = []\n",
        "\n",
        "for i in range(movie_similarity_csr.shape[0]):\n",
        "    #Extrai a linha i (similaridade do filme i com todos os outros)\n",
        "    row = movie_similarity_csr.getrow(i).toarray().ravel()\n",
        "\n",
        "    #Zera similaridades negativas para ignorá-las\n",
        "    row[row < 0] = 0\n",
        "\n",
        "    #Remove o próprio item (autossimilaridade = 1)\n",
        "    row[i] = 0\n",
        "\n",
        "    #Seleciona apenas os índices dos K maiores valores positivos\n",
        "    topk_idx = np.argsort(row)[-K:][::-1]  #pega os maiores K\n",
        "    topk_values = row[topk_idx]\n",
        "\n",
        "    #Remove zeros do resultado (caso o item tenha < K positivos)\n",
        "    valid_mask = topk_values > 0\n",
        "    topk_idx = topk_idx[valid_mask]\n",
        "    topk_values = topk_values[valid_mask]\n",
        "\n",
        "    indices_topk.append(topk_idx)\n",
        "    values_topk.append(topk_values)\n",
        "\n",
        "#Agora, indices_topk[i] contém os índices dos vizinhos positivos mais similares ao item i\n",
        "#e values_topk[i] contém os respectivos valores de similaridade"
      ],
      "metadata": {
        "id": "vpkKqmePbSAR"
      },
      "id": "vpkKqmePbSAR",
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "4f17a3cd-902e-41a8-9981-16d86725c771",
      "metadata": {
        "id": "4f17a3cd-902e-41a8-9981-16d86725c771"
      },
      "outputs": [],
      "source": [
        "#Função para recomendar filmes similares\n",
        "#Retorna os top_n filmes mais similares a um movie_id dado\n",
        "#Usa apenas os vizinhos positivos mais similares do filme como base de recomendação -- ou seja, substitui a parte onde pega todos os scores pela lista indices_topk[movie_idx].\n",
        "def recommend_movies(movie_id, top_n):\n",
        "    #Verifica se o filme existe no mapeamento\n",
        "    if movie_id not in movie_mapper:\n",
        "        print(f\"Filme {movie_id} não encontrado.\")\n",
        "        return []\n",
        "\n",
        "    #Obtém o índice interno do filme\n",
        "    movie_idx = movie_mapper[movie_id]\n",
        "\n",
        "    #Obtém vizinhos mais similares pré-calculados (Top-K)\n",
        "    topk_indices = indices_topk[movie_idx]\n",
        "    topk_values = values_topk[movie_idx]\n",
        "\n",
        "    #Cria uma série (índice = índice do filme, valor = similaridade)\n",
        "    sim_series = pd.Series(topk_values, index=topk_indices)\n",
        "\n",
        "    #Seleciona os Top N (ou menos, se houver menos que N vizinhos)\n",
        "    top_indices = sim_series.sort_values(ascending=False).iloc[:top_n].index\n",
        "\n",
        "    #Monta lista de recomendações com títulos e similaridades\n",
        "    recommendations = []\n",
        "    for idx in top_indices:\n",
        "        mid = movie_inv_mapper[idx]                                   #Converte índice interno de volta para movieId original\n",
        "        title = movies.loc[movies.movieId == mid, 'title'].values[0]  #Busca título do filme\n",
        "        score = sim_series[idx]                                       #Similaridade calculada\n",
        "        recommendations.append((title, score))\n",
        "\n",
        "    return recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "50045a30-4158-4b15-bba7-f207707aad61",
      "metadata": {
        "id": "50045a30-4158-4b15-bba7-f207707aad61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af4836d5-1384-4aeb-c4c9-882ae243a14c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 15 filmes similares a 'Toy Story (1995)':\n",
            "Toy Story 2 (1999) — similaridade 0.403\n",
            "Toy Story 3 (2010) — similaridade 0.327\n",
            "Aladdin (1992) — similaridade 0.327\n",
            "Wallace & Gromit: The Wrong Trousers (1993) — similaridade 0.305\n",
            "Back to the Future (1985) — similaridade 0.277\n",
            "Incredibles, The (2004) — similaridade 0.275\n",
            "Blazing Saddles (1974) — similaridade 0.272\n",
            "Finding Nemo (2003) — similaridade 0.263\n",
            "Ghostbusters (a.k.a. Ghost Busters) (1984) — similaridade 0.250\n",
            "Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981) — similaridade 0.237\n",
            "Lion King, The (1994) — similaridade 0.235\n",
            "True Grit (1969) — similaridade 0.226\n",
            "Hugo (2011) — similaridade 0.224\n",
            "E.T. the Extra-Terrestrial (1982) — similaridade 0.224\n",
            "Mary Poppins (1964) — similaridade 0.224\n"
          ]
        }
      ],
      "source": [
        "#Testar recomendações para um filme\n",
        "\n",
        "#Exemplo: movieId = 1 (Toy Story 1995)\n",
        "movie_id = 1\n",
        "top_n=15\n",
        "top_movies = recommend_movies(movie_id, top_n)\n",
        "\n",
        "print(f\"Top {top_n} filmes similares a '{movies.loc[movies.movieId==movie_id,'title'].values[0]}':\")\n",
        "for title, score in top_movies:\n",
        "    print(f\"{title} — similaridade {score:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "2fed2c65-2ab1-48aa-9c17-404982a48387",
      "metadata": {
        "id": "2fed2c65-2ab1-48aa-9c17-404982a48387"
      },
      "outputs": [],
      "source": [
        "#Função para recomendar para um usuário\n",
        "#Retorna recomendações para um usuário baseado em ratings passados e similaridade filme-filme\n",
        "def recommend_for_user(user_id, top_n=5):\n",
        "    #Obter índice do usuário\n",
        "    if user_id not in user_mapper:\n",
        "        print(f\"Usuário {user_id} não encontrado.\")\n",
        "        return []\n",
        "\n",
        "    #Converte user_id original para o índice interno da matriz\n",
        "    user_idx = user_mapper[user_id]\n",
        "\n",
        "    #Filmes avaliados pelo usuário (linha do usuário na matriz)\n",
        "    #Converte a linha esparsa para array e achata para vetor 1D\n",
        "    user_ratings = ratings_sparse[user_idx, :].toarray().flatten()\n",
        "\n",
        "    #Pega os índices dos filmes avaliados (notas > 0)\n",
        "    rated_indices = np.where(user_ratings > 0)[0]\n",
        "\n",
        "    #Vetores para armazenar soma ponderada dos scores e soma das similaridades\n",
        "    scores = np.zeros(ratings_sparse.shape[1])\n",
        "    sim_sums = np.zeros(ratings_sparse.shape[1])\n",
        "\n",
        "    '''Para cada filme avaliado, acumular score ponderado:\n",
        "       - pega os vizinhos Top-K desse filme\n",
        "       - multiplica a similaridade de cada vizinho pela nota do usuário\n",
        "       - acumula as somas para depois normalizar'''\n",
        "    for idx in rated_indices:\n",
        "        sim_indices = indices_topk[idx]   # índices dos vizinhos Top-K\n",
        "        sim_values = values_topk[idx]     # valores das similaridades Top-K\n",
        "        rating = user_ratings[idx]        # nota (normalizada) que o usuário deu ao filme\n",
        "\n",
        "        #Acumula soma ponderada e normalizador\n",
        "        scores[sim_indices] += sim_values * rating\n",
        "        sim_sums[sim_indices] += sim_values\n",
        "\n",
        "    #Evita divisão por zero\n",
        "    sim_sums[sim_sums == 0] = 1\n",
        "\n",
        "    #Nota prevista normalizada = soma ponderada / soma das similaridades\n",
        "    predicted_ratings = scores / sim_sums\n",
        "\n",
        "    #---------IMPORTANTE: REVERTER NORMALIZAÇÃO PARA ESCALA ORIGINAL---------\n",
        "    #user_avg = user_mean.loc[user_id]                 #média real do usuário\n",
        "    #predicted_ratings = predicted_ratings + user_avg  #soma de volta à média\n",
        "\n",
        "    #Limita à escala válida do MovieLens (0.5 a 5.0)\n",
        "    #predicted_ratings = np.clip(predicted_ratings, 0.5, 5.0)\n",
        "\n",
        "    #Remove filmes já avaliados (não queremos recomendá-los novamente)\n",
        "    predicted_ratings[rated_indices] = 0\n",
        "\n",
        "    #Seleciona os filmes com maiores notas previstas\n",
        "    top_indices = np.argsort(predicted_ratings)[::-1][:top_n]\n",
        "\n",
        "    #Monta a lista final de recomendações (título e nota prevista)\n",
        "    recommendations = []\n",
        "    for idx in top_indices:\n",
        "        mid = movie_inv_mapper[idx]   # converte índice interno para movieId original\n",
        "        title = movies.loc[movies.movieId == mid, 'title'].values[0]\n",
        "        recommendations.append((title, predicted_ratings[idx]))\n",
        "\n",
        "    return recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "eb300824-2460-42a0-913c-be44e6e56cdc",
      "metadata": {
        "id": "eb300824-2460-42a0-913c-be44e6e56cdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ef78c80-2224-4e7f-ff82-efe27f8f01fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 recomendações para o usuário 18:\n",
            "Alphaville (Alphaville, une étrange aventure de Lemmy Caution) (1965) — score 1.268\n",
            "All Dogs Go to Heaven 2 (1996) — score 1.268\n",
            "Boiling Point (1993) — score 1.268\n",
            "Tender Mercies (1983) — score 1.268\n",
            "Stepford Wives, The (1975) — score 1.268\n"
          ]
        }
      ],
      "source": [
        "#Testar recomendações para um usuário\n",
        "\n",
        "user_id = 18\n",
        "top_user_movies = recommend_for_user(user_id, top_n=5)\n",
        "\n",
        "print(f\"Top 5 recomendações para o usuário {user_id}:\")\n",
        "for title, score in top_user_movies:\n",
        "    print(f\"{title} — score {score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## O que muda ao usar o Top-K\n",
        "Na nova versão:\n",
        "- predicted_ratings = scores / sim_sums;\n",
        "- scores = soma das similaridades × nota do usuário;\n",
        "- sim_sums = soma somente dos Top-K vizinhos relevantes;\n",
        "\n",
        "E como estamos somando K vizinhos com similaridade real (ex: 0.7, 0.6, 0.5), o denominador (sim_sums) tende a ser pequeno (~3-6).\n",
        "\n",
        "- Isso faz com que o resultado final (predicted_ratings) caia naturalmente para a escala das notas originais (0-5).\n",
        "- Agora estamos efetivamente prevendo notas normalizadas, e não apenas acumulando força bruta.\n",
        "\n",
        "Portanto, valores como 1.268 agora significam algo do tipo: “O modelo prevê que o usuário daria nota 1.27 para esse filme.”\n",
        "\n",
        "**SEM** A NORMALIZAÇÃO DE VOLTA PARA A ESCALA ORIGINAL VÁLIDA DO MOVIELENS, o modelo está prevendo quanto acima ou abaixo da média o usuário tenderia a avaliar, não a nota final ainda.\n",
        "\n",
        "\n",
        "Tomemos o usuário 18 de exemplo. Top 5 recomendações para o usuário 18 com k=100:\n",
        "- Alphaville (Alphaville, une étrange aventure de Lemmy Caution) (1965) — score 1.268\n",
        "- All Dogs Go to Heaven 2 (1996) — score 1.268\n",
        "- Boiling Point (1993) — score 1.268\n",
        "- Tender Mercies (1983) — score 1.268\n",
        "- Stepford Wives, The (1975) — score 1.268\n",
        "\n",
        "O sistema está prevendo valores em torno de zero:\n",
        "- 0 → filme médio para o usuário\n",
        "- +1.0 → filme que ele tenderia a avaliar 1 ponto acima da média\n",
        "- -1.0 → filme que ele tenderia a avaliar 1 ponto abaixo da média\n",
        "\n",
        "Ao somar +3.73 (média pessoal dele), obtém-se previsões em torno de 3.73 ± 1, ou seja, na escala original (0.5–5.0)."
      ],
      "metadata": {
        "id": "-vcqzLUbpkv_"
      },
      "id": "-vcqzLUbpkv_"
    },
    {
      "cell_type": "code",
      "source": [
        "#GEPETO: BLOCO GERADO PARA DIAGNÓSTICOS RÁPIDOS\n",
        "\n",
        "#1) intervalo das notas no dataset original\n",
        "print(\"ratings range:\", ratings['rating'].min(), ratings['rating'].max())\n",
        "print(\"ratings mean overall:\", ratings['rating'].mean())\n",
        "\n",
        "#2) verificar se você tem coluna normalizada (rating_norm) e se ratings_sparse usa ela\n",
        "print(\"rating_norm present:\", 'rating_norm' in ratings.columns)\n",
        "#Se ratings_sparse foi reconstruída a partir de ratings['rating_norm'], verifique:\n",
        "example_user = 442\n",
        "print(\"média do usuário\", example_user, \":\", ratings.groupby('userId')['rating'].mean().loc[example_user])\n",
        "print(\"user_ratings (sample) for user 18:\", ratings_sparse[user_mapper[example_user], :].toarray().flatten()[ :10 ])\n",
        "\n",
        "#3) estatísticas das similaridades Top-K para um filme exemplo\n",
        "movie_idx = 2\n",
        "vals = values_topk[movie_idx] if 'values_topk' in globals() else movie_similarity[movie_idx].toarray().flatten()\n",
        "print(\"similarity stats (example movie): min, max, mean, sum:\", np.min(vals), np.max(vals), np.mean(vals), np.sum(vals))\n",
        "\n",
        "#4) rodar recommend_for_user e inspecionar sim_sums / predicted_ratings internamente\n",
        "user_id = 442\n",
        "user_idx = user_mapper[user_id]\n",
        "user_ratings = ratings_sparse[user_idx,:].toarray().flatten()\n",
        "rated_indices = np.where(user_ratings>0)[0]\n",
        "\n",
        "#Compute sim_sums & scores as in your Top-K version\n",
        "scores = np.zeros(ratings_sparse.shape[1])\n",
        "sim_sums = np.zeros(ratings_sparse.shape[1])\n",
        "for idx in rated_indices:\n",
        "    sim_idx = indices_topk[idx]\n",
        "    sim_val = values_topk[idx]\n",
        "    scores[sim_idx] += sim_val * user_ratings[idx]\n",
        "    sim_sums[sim_idx] += sim_val\n",
        "\n",
        "print(\"sim_sums stats:\", sim_sums.min(), np.percentile(sim_sums,25), np.median(sim_sums), np.mean(sim_sums), sim_sums.max())\n",
        "pred = scores / np.where(sim_sums==0, 1, sim_sums)\n",
        "print(\"predicted ratings stats:\", pred.min(), np.percentile(pred,25), np.median(pred), np.mean(pred), pred.max())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eK91YpdkTtq",
        "outputId": "a9468b38-22c2-4c0a-ca30-12edf0d71bf7"
      },
      "id": "3eK91YpdkTtq",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ratings range: 0.5 5.0\n",
            "ratings mean overall: 3.501556983616962\n",
            "rating_norm present: True\n",
            "média do usuário 442 : 1.275\n",
            "user_ratings (sample) for user 18: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "similarity stats (example movie): min, max, mean, sum: 0.22215172888848148 0.3507745103783537 0.23575215303455174 23.575215303455174\n",
            "sim_sums stats: 0.0 0.0 0.0 0.02777567959857245 0.757237232655326\n",
            "predicted ratings stats: 0.0 0.0 0.0 0.053067961507589835 1.2250000000000003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Descobrir o usuário com menor média de avaliações\n",
        "lowest_user = user_mean.idxmin()       #retorna o userId com menor média\n",
        "lowest_mean = user_mean.min()          #valor da menor média\n",
        "\n",
        "print(f\"Usuário com menor média: {lowest_user} (média = {lowest_mean:.3f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT24s3hcn-BT",
        "outputId": "63c30f23-155f-4d05-e2c9-0c95669bf347"
      },
      "id": "pT24s3hcn-BT",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usuário com menor média: 442 (média = 1.275)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Média do usuário:\", user_mean.loc[442])\n",
        "print(\"Número de filmes avaliados:\", len(np.where(ratings_sparse[user_mapper[442], :].toarray().flatten() > 0)[0]))\n",
        "\n",
        "#Avaliar dispersão das predições\n",
        "pred = recommend_for_user(442, top_n=5)\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSHUIUIiofTd",
        "outputId": "a7c94b22-6c3c-47e8-cf19-a55cf7f37a60"
      },
      "id": "JSHUIUIiofTd",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do usuário: 1.275\n",
            "Número de filmes avaliados: 9\n",
            "[('Pom Poko (a.k.a. Raccoon War, The) (Heisei tanuki gassen pompoko) (1994)', np.float64(2.5)), ('Great Expectations (1946)', np.float64(2.5)), ('Doctor Who: The Time of the Doctor (2013)', np.float64(2.5)), ('Real Blonde, The (1997)', np.float64(2.5)), ('Talk to Her (Hable con Ella) (2002)', np.float64(2.5))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 5 recomendações para o usuário 442, com k=100:\n",
        "- Real Blonde, The (1997) — score 1.225\n",
        "- Summer Place, A (1959) — score 1.225\n",
        "- Beyond the Clouds (Al di là delle nuvole) (1996) — score 1.225\n",
        "- Total Eclipse (1995) — score 1.225\n",
        "- Final Analysis (1992) — score 1.225\n",
        "\n",
        "Usuário 442 dá notas extremamente baixas (bem abaixo da média geral ≈ 3.5). Seu vetor de avaliações é muito esparso e de baixo valor, com 9 filmes avaliados.\n",
        "\n",
        "Durante a predição, como normalizamos as notas (rating_norm = rating - user_mean), esse usuário 442 tem praticamente notas normalizadas próximas de 0.\n",
        "\n",
        "Isso faz com que o acumulador\n",
        "`scores[sim_indices] += sim_values * rating`\n",
        "resulte em valores muito baixos ou quase nulos (porque rating ≈ 0 ou até negativo, e sim_values pequenas).\n",
        "\n",
        "Na normalização, mesmo após dividir por sim_sums,\n",
        "- `predicted_ratings = scores / sim_sums`\n",
        "- `predicted_ratings += user_avg  #soma a média dele (1.275)`\n",
        "\n",
        "as notas previstas se concentram em torno da média pessoal dele -- ou seja, tudo fica ≈ 1.27.\n",
        "\n",
        "Mas como aplicamos np.clip(predicted_ratings, 0.5, 5.0) e np.where(...),\n",
        "ainda podendo haver arredondamentos internos,\n",
        "o valor final pode ser arredondado ou truncado para algo como 2.5,\n",
        "especialmente se a matriz de similaridade for muito diluída (top-K pequeno ou falta de vizinhos relevantes).\n",
        "\n",
        "Além disso, como avaliou poucos filmes (9) com notas baixas (média = 1.275), o modelo tem pouquíssima informação para inferir o gosto dele.\n",
        "\n",
        "O algoritmo item-based tenta prever algo assim:\n",
        "> “Se ele gostou de filme A, então talvez também goste de filme B semelhante.”\n",
        "\n",
        "Mas… se ele não gostou de quase nada, não há ponto de referência positivo.\n",
        "Logo, o modelo fica meio “sem chão”, e retorna um valor neutro (2.5) porque:\n",
        "- é o centro da escala (entre 0.5 e 5.0),\n",
        "- e o cálculo ponderado por similaridade tende a convergir para esse meio termo quando os pesos são fracos ou cancelam entre si.\n",
        "\n",
        "\n",
        "Sim, escrevi esse textão todo só pra demonstrar como esse comportamento é normal. O modelo está apenas sendo honesto: “Eu não tenho informação suficiente para sugerir algo com confiança, então fico no meio da escala.”\n",
        "\n",
        "O que observamos aqui é um dos fenômenos mais clássicos da área: o chamado “cold start” (início frio)."
      ],
      "metadata": {
        "id": "VIr0iFQBsjyX"
      },
      "id": "VIr0iFQBsjyX"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}